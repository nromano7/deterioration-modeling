{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "RANDOM_SEED = 0\n",
    "tf.set_random_seed(RANDOM_SEED)\n",
    "%run initialize_interactivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "raw_data = pd.read_excel('./nation_data.xlsx')\n",
    "\n",
    "# drop unwated columns\n",
    "raw_data.drop(['8 - Structure Number'],axis=1,inplace=True)\n",
    "\n",
    "# drop columns with nan\n",
    "raw_data.dropna(axis=1,how='all',inplace=True)\n",
    "\n",
    "# fill nan values with 0\n",
    "raw_data.fillna(value=0, inplace=True)\n",
    "\n",
    "# replace 0 values with error code\n",
    "replace = {'58 - Deck': {0 : '99 - Null Value'}}\n",
    "raw_data.replace(to_replace=replace, inplace=True)\n",
    "\n",
    "# factorize categorical variables and create dict of preprocessed data\n",
    "categorical_data = {}\n",
    "data_dict = {}\n",
    "for i,x in enumerate(raw_data.dtypes.values): \n",
    "    col = raw_data.columns[i] \n",
    "    if x == object:        \n",
    "        categorical_data[col] = pd.factorize(raw_data[col])\n",
    "        data_dict[col] = categorical_data[col][0]\n",
    "    else:\n",
    "        data_dict[col] = raw_data[col]\n",
    "        \n",
    "# create dataframe of preprocessed data        \n",
    "data = pd.DataFrame(data_dict,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract features and targets\n",
    "features = data.drop(['58 - Deck'],axis=1)\n",
    "target = data['58 - Deck']\n",
    "\n",
    "# add bias term to features\n",
    "features.insert(0,'bias',np.float32(1))\n",
    "\n",
    "# convert targets into one-hot vectors\n",
    "num_labels = len(target.unique())\n",
    "target = pd.get_dummies(target)\n",
    "\n",
    "# convert to type: ndarray\n",
    "features = features.as_matrix()\n",
    "target = target.as_matrix()\n",
    "train_X, test_X, train_y, test_y = train_test_split(features, target, test_size=0.25, random_state=RANDOM_SEED)\n",
    "\n",
    "# get shape values\n",
    "shape_X = train_X.shape\n",
    "shape_y = train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "N_INPUTS = shape_X[1]\n",
    "N_OUTPUTS = shape_y[1]\n",
    "\n",
    "# tuning parameters\n",
    "hidden_layers = 1\n",
    "hidden_size = 10\n",
    "learning_rate = 0.05\n",
    "\n",
    "# initialize placeholders for inputs, outputs, and weight tensors\n",
    "X = tf.placeholder(tf.float32, shape = [None, N_INPUTS], name = \"X\")\n",
    "y = tf.placeholder(tf.float32, shape = [None, N_OUTPUTS], name = \"y\")\n",
    "w1 = tf.Variable(tf.random_normal((N_INPUTS, hidden_size), stddev=0.1))\n",
    "w2 = tf.Variable(tf.random_normal((hidden_size, N_OUTPUTS), stddev=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# forward propogation using the soigmoid activation function\n",
    "z1 = tf.nn.sigmoid(tf.matmul(X, w1))  \n",
    "z2 = tf.matmul(z1, w2)  \n",
    "predictions = tf.argmax(z2, axis=1) # get column with largest activation value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# back propogation: reducing the mean error of softmax function\n",
    "error = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=z2))\n",
    "optm = tf.train.GradientDescentOptimizer(learning_rate).minimize(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step = 0, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 10, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 20, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 30, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 40, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 50, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 60, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 70, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 80, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 90, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 100, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 110, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 120, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 130, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 140, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 150, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 160, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 170, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 180, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 190, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 200, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 210, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 220, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 230, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 240, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 250, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 260, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 270, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 280, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 290, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 300, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 310, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 320, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 330, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 340, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 350, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 360, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 370, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 380, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 390, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 400, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 410, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 420, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 430, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 440, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 450, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 460, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 470, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 480, train accuracy = 0.0%, test accuracy = 0.0%\n",
      "Step = 490, train accuracy = 0.0%, test accuracy = 0.0%\n"
     ]
    }
   ],
   "source": [
    "# initialize the session and global variables\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# run the gradient decent to optimize the \n",
    "for steps in range(500):\n",
    "    \n",
    "    # Train with each example\n",
    "    for n in range(shape_X[0]):    \n",
    "        sess.run(optm, feed_dict = {X: train_X[n: n+1], y: train_y[n: n+1]})\n",
    "\n",
    "    train_accuracy = np.mean(tf.argmax(train_y, axis=1) == sess.run(predictions, feed_dict={X: train_X, y: train_y}))\n",
    "    test_accuracy  = np.mean(tf.argmax(test_y, axis=1) == sess.run(predictions, feed_dict={X: test_X, y: test_y}))\n",
    "\n",
    "    if steps % 10 == 0:\n",
    "        print(f\"Step = {steps}, train accuracy = {round(100*train_accuracy,4)}%, test accuracy = {round(100*test_accuracy,4)}%\")\n",
    "\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
